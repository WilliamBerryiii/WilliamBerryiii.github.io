---
layout: post
title: Performance Tuning During Development
date: '2014-06-05T22:41:00.001-07:00'
author: William Berry
tags:
- APIs
- Data Structures
- C#
- Performance Tuning
modified_time: '2014-06-06T00:46:27.550-07:00'
blogger_id: tag:blogger.com,1999:blog-4707687462195457004.post-9204496810526337055
blogger_orig_url: http://www.lucidmotions.net/2014/06/performance-tuning-during-development.html
---

The day (and lately, night) job has been focused on a data api backing a new business insights tool. &nbsp;Despite concerted efforts by nefarious interests, we have managed to keep the API resource centric, only leaking behavior where absolutely necessary. &nbsp;We are starting the process of putting internal customers in front of the tool, and as such, I have become increasingly aware of the performance issues, of which there are quite a few. <br><div><br></div><div>The API provides an abstraction over two different persistence store technologies (Sql Server &amp; HBase) and the domain models are built from data that resides in both stores. &nbsp;No one particular resource channel is slow, but in the aggregate it *could* be more performant. &nbsp;We have been working hard over the last few days to weave instrumentation into the application using Semantic Logging, and I figured, while I was down in bowels, I could investigate what I perceived to be performance problems. &nbsp;</div><div><br></div><div>I started with the usual Visual Studio performance tooling ... fire up Performance Analyzer and run all of the stock wizard tests one by one (except for the contention test - I am not convinced it ever really gives useful information). &nbsp;These tests should be focused and limited in scope. &nbsp;Running the analyzer for 20 min and exploring every corner of your API is for another time. &nbsp;Here we are just trying to keep tabs on sticky or overly complex code blocks and you really just need to scout for a few key data points:</div><div><ul><li>What methods in your stack or in the core libs are called most often? What is their percentage of total calls?</li><li>What blocks of code are flagged in the hotlines graph?</li><li>Where is most of the processing time spent?</li><li>What spends the most time waiting for other methods to finish?</li></ul><div>Don't spend more than a few min just skimming the reports, remembering that you are here purely to simplify data structures, make your code cleaner and maybe a bit faster. &nbsp;</div></div><div><br></div><div>Below is a classic example of scaffolded code that I started a new algorithm off with. &nbsp;It was filled in with business logic, and then became a blight on the system.</div><div><br></div><div>First the scaffold code:</div><div><br></div><div><pre><span style="color: teal;">  1</span> var dedupedEdges = <span style="color: blue;">new</span> List&lt;Tuple&lt;<span style="color: blue;">string</span>, <span style="color: blue;">string</span>&gt;&gt;(); <br /><span style="color: teal;">  2</span> <span style="color: blue;">foreach</span> (var edge <span style="color: blue;">in</span> edgeGroups.SelectMany(x =&gt; x.EdgeList))<br /><span style="color: teal;">  3</span>     <span style="color: green;">// Make sure both points are not "green"</span> <br /><span style="color: teal;">  4</span>     <span style="color: green;">// Tuple is not in list as (item1, item2)</span> <br /><span style="color: teal;">  5</span>     <span style="color: green;">// Tuple is not in list as (item2, item1)</span>&nbsp;</pre><pre><span style="color: teal;">  6</span>     { <br /><span style="color: teal;">  7</span>     dedupedEdges.Add(<span style="color: blue;">new</span> Tuple&lt;<span style="color: blue;">string</span>, <span style="color: blue;">string</span>&gt;(<span style="color: maroon;">""</span>,<span style="color: maroon;">""</span>)); <br /><span style="color: teal;">  8</span>     }</pre></div><div><br></div><div>After writing a few failing tests we have a naive implementation ... that works perfect over the small data set we are unit testing against. <br><br>The code as first implemented:<br><br><div><pre><span style="color: teal;">  1</span> var dedupedEdges = <span style="color: blue;">new</span> List&lt;Tuple&lt;<span style="color: blue;">string</span>, <span style="color: blue;">string</span>&gt;&gt;(); <br /><span style="color: teal;">  2</span> <span style="color: blue;">foreach</span> (var edge <span style="color: blue;">in</span> edgeGroups.SelectMany(x =&gt; x.EdgeList)<br /><span style="color: teal;">  3</span>     .Where(x =&gt; !x.Item1.IsGreen() || !x.Item2.IsGreen()) <br /><span style="color: teal;">  4</span>     .Where(edge =&gt; !dedupedEdges <br /><span style="color: teal;">  5</span>         .Contains(<span style="color: blue;">new</span> Tuple&lt;<span style="color: blue;">string</span>, <span style="color: blue;">string</span>&gt;(edge.Item1, edge.Item2))) <br /><span style="color: teal;">  6</span>     .Where(edge =&gt; !dedupedEdges <br /><span style="color: teal;">  7</span>         .Contains(<span style="color: blue;">new</span> Tuple&lt;<span style="color: blue;">string</span>, <span style="color: blue;">string</span>&gt;(edge.Item2, edge.Item1)))) <br /><span style="color: teal;">  8</span>     { <br /><span style="color: teal;">  9</span>     dedupedEdges.Add(<span style="color: blue;">new</span> Tuple&lt;<span style="color: blue;">string</span>, <span style="color: blue;">string</span>&gt;(edge.Item1, edge.Item2)); <br /><span style="color: teal;"> 10</span>     }</pre></div><br>Now I am not proud of this code; it's repetitive and poorly designed. &nbsp;But, it's also done, working and passing all the tests. &nbsp;<i>Don't fool yourself, if you write enough code, day in and day out ... a non-neglible percentage is pure drivel like this. </i><br><br>So I am merrily flipping through the reports only to find that I am making 1.25 million ... yes I said MILLION calls to Tuple.Item1 and another 1.25 million calls to Tuple.Item2 during one very large API call. &nbsp;So following the hotlines graph, I am kindly directed by Visual Studio to the crap starting on line 2. &nbsp;Knowing better than to just start hacking away at it, as my instincts directed, I put in some code to help me understand the severity of the problem first. &nbsp;<i>"If it ain't Baroque don't fix it"</i><br><br>Stopwatch() ... as the guys on DotNetRocks say "<i>know it, learn it, love it.</i>" &nbsp;I dropped one around this &nbsp;block with a handy little <i>Debug.Print(Stopwatch.EllapsedMiliseconds)</i> and found my 2.5 million calls to Tuple.Item* were taking 1753ms, over an average of 10 runs across this code. &nbsp;First, the .Net framework can clearly make very, very bad code run not so badly. &nbsp;Second, I clearly have a demonstrable problem here.<br><br>When I <strike>wrote</strike>&nbsp;phoned in this code, I was focused on the bigger algorithm at hand ... "pass the tests and move on." &nbsp;But now, armed with metrics, I have justifiable cause to go a'hacking. <br><br>There are a number of things that need to be fixed, but let's first take a look at what this code is supposed to do.<br><ul><li>The usage of <i>SelectMany</i> indicates in this context that we are iterating a child list of multiple <i>EdgeGroups</i>.</li><li>An <i>Edge</i> is a <i>Tuple</i>&lt;<i>string</i> &amp; <i>string&gt;.</i></li><li>The first predicate filter makes sure both elements are not "<i>green</i>" (whatever <i>green</i> means).</li><li>We then check the <i>dedupedEdges</i>&nbsp;<i>List</i> to make sure a new version of the&nbsp;<i>Tuple</i> is not already in the list.</li><li>We next check the <i>dedupedEdges</i> <i>List</i> to make sure the reversed <i>Tuple</i> is not in the list.</li><li>Finally take the Tuple, decompose it, rebuild a new tuple and finally add it to the&nbsp;<i>dedupedEdges</i>&nbsp;<i>List</i>.</li></ul><div>What, pray tell, could possibly be wrong here? &nbsp;Let's go through each step and see if we can't make this better, shall we?</div><div><br></div><div>Well the first step is to not use a crappy data structure. &nbsp;What we need here is a Set, someplace where we can only stick 1 of an item and not end up with any duplicates. &nbsp;Additionally, we need to do fast lookups into the data structure to make sure the reversed tuple is not present. &nbsp;Hello, <a href="http://msdn.microsoft.com/en-us/library/bb397727(v=vs.110).aspx">HashSet</a>. &nbsp;Let's see what this code looks like after a refactor:</div><div><br></div><div><pre><span style="color: teal;">  1</span> var dedupedEdges = <span style="color: blue;">new</span> HashSet&lt;Tuple&lt;<span style="color: blue;">string</span>, <span style="color: blue;">string</span>&gt;&gt;(); <br /><span style="color: teal;">  2</span> <span style="color: blue;">foreach</span> (var edge <span style="color: blue;">in</span> edgeGroups.SelectMany(x =&gt; x.EdgeList)<br /><span style="color: teal;">  3</span>     .Where(x =&gt; !x.Item1.IsGreen() || !x.Item2.IsGreen()) <br /><span style="color: teal;">  4</span>     .Where(edge =&gt; !idIncludedEdges.Contains( <br /><span style="color: teal;">  5</span>         <span style="color: blue;">new</span> Tuple&lt;<span style="color: blue;">string</span>, <span style="color: blue;">string</span>&gt;(edge.Item2, edge.Item1)))) <br /><span style="color: teal;">  6</span>     { <br /><span style="color: teal;">  7</span>     dedupedEdges.Add(edge); <br /><span style="color: teal;">  8</span>     }</pre></div><div><br></div><div>The loop still does the original predicate on green-ness; but now, we are doing do a highly performant lookup on the reverse tuple construct and finish by blindly tossing the filtered items at the HashSet which will ensure uniqueness for us. <br><br>Is this perfect? &nbsp;Nope. <br>Could it be better? &nbsp;Sure. <br>Do I care? Nope. <br><br>I get paid to write code ... hopefully, a lot of code. &nbsp;If I can produce that code quickly great! &nbsp;If that code is quick itself, greater sill! &nbsp;If someone else can understand my quickly generated, quick code - I can stop for the day, as I have succeeded.<br><br>So, the totally unscientific performance boost from this refactor ... 1753ms ... to an average of 5ms over 10 iterations. <br><br>Core Takeaway:<br><br><ul><li>You can do "some" performance work during development without hindering forward progress.</li><li>If you chose to do performance during active development, keep your efforts reasonable.</li><li>Deep dives while you are still developing an algorithm are distracting.</li><li>Often you can make huge performance gains without changing the shape of the code.</li><li>You will write crappy code and 90% of the time ... thats OK.</li><li>Know that you write crappy code, own it, hunt for it, fix it.</li></ul></div><br></div>